{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N4f88K1-MdqF"
      },
      "outputs": [],
      "source": [
        "# Cell 1 - Setup\n",
        "# Only standard Python + requests + openai\n",
        "!pip install --quiet openai requests\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from getpass import getpass\n",
        "from typing import List, Dict, Any, Tuple\n",
        "import requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 - Get API key safely at runtime (do NOT hardcode)\n",
        "# Option A: Put your GROQ_API_KEY into an env var in Colab before running:\n",
        "#   import os; os.environ['GROQ_API_KEY'] = \"sk-...\"\n",
        "# Option B: Enter interactively (preferred for interactive testing)\n",
        "key = os.environ.get(\"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\")\n",
        "if not key:\n",
        "    print(\"Please paste your Groq API key (it will not be shown):\")\n",
        "    key = getpass(\"GROQ API KEY: \")\n",
        "    # for safety, do not persist to disk\n",
        "    os.environ[\"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\"] = key\n",
        "\n",
        "API_KEY = key\n",
        "BASE_URL = \"https://api.groq.com/openai/v1\"  # Groq's OpenAI-compatible base URL\n",
        "print(\"API key loaded into environment (not shown). Base URL:\", BASE_URL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdJbSBwOMrMh",
        "outputId": "02de4775-b290-4b94-fe0a-f0a2e65c3180"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please paste your Groq API key (it will not be shown):\n",
            "GROQ API KEY: ··········\n",
            "API key loaded into environment (not shown). Base URL: https://api.groq.com/openai/v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 - helper to call Groq OpenAI-compatible Chat Completions\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "def groq_chat_completion(messages: List[Dict[str,str]],\n",
        "                         model: str = \"openai/gpt-oss-20b\",\n",
        "                         temperature: float = 0.2,\n",
        "                         functions: List[Dict] = None,\n",
        "                         function_call: Any = None,\n",
        "                         max_tokens: int = 512) -> Dict:\n",
        "    \"\"\"\n",
        "    Minimal wrapper around Groq Chat Completions endpoint (OpenAI-compatible).\n",
        "    If functions is provided, it passes them through for function-calling behavior.\n",
        "    \"\"\"\n",
        "    url = f\"{BASE_URL}/chat/completions\"\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": messages,\n",
        "        \"temperature\": temperature,\n",
        "        \"max_tokens\": max_tokens\n",
        "    }\n",
        "    if functions is not None:\n",
        "        payload[\"functions\"] = functions\n",
        "    if function_call is not None:\n",
        "        payload[\"function_call\"] = function_call  # e.g., \"auto\" or specific function name\n",
        "\n",
        "    r = requests.post(url, headers=HEADERS, json=payload, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n"
      ],
      "metadata": {
        "id": "AddGO2lJO7yb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 - Conversation store and truncation/summarization hooks\n",
        "\n",
        "class ConversationStore:\n",
        "    def __init__(self):\n",
        "        # store messages as list of {\"role\": \"user\"|\"assistant\"|\"system\", \"content\": \"text\"}\n",
        "        self.history: List[Dict[str,str]] = []\n",
        "        self.run_count = 0\n",
        "\n",
        "    def add_message(self, role: str, content: str):\n",
        "        self.history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "    def get_last_n_turns(self, n: int) -> List[Dict[str,str]]:\n",
        "        # A \"turn\" = user + assistant; keep last n user/assistant pairs approx.\n",
        "        if n <= 0:\n",
        "            return []\n",
        "        # Build turns from history; simpler approach: take last (2*n) messages\n",
        "        return self.history[-2*n:]\n",
        "\n",
        "    def get_by_char_limit(self, char_limit: int) -> List[Dict[str,str]]:\n",
        "        # return last messages until combined char length <= char_limit\n",
        "        out = []\n",
        "        total = 0\n",
        "        for msg in reversed(self.history):\n",
        "            l = len(msg[\"content\"])\n",
        "            if total + l > char_limit and out:\n",
        "                break\n",
        "            out.insert(0, msg)\n",
        "            total += l\n",
        "        return out\n",
        "\n",
        "    def get_by_word_limit(self, word_limit: int) -> List[Dict[str,str]]:\n",
        "        out = []\n",
        "        total = 0\n",
        "        for msg in reversed(self.history):\n",
        "            w = len(msg[\"content\"].split())\n",
        "            if total + w > word_limit and out:\n",
        "                break\n",
        "            out.insert(0, msg)\n",
        "            total += w\n",
        "        return out\n",
        "\n",
        "    def replace_with_summary(self, summary_text: str):\n",
        "        # Replace entire history with a short system summary + keep last user message (if any)\n",
        "        preserved_tail = self.history[-1:] if self.history else []\n",
        "        self.history = [{\"role\":\"system\", \"content\": f\"Summary of previous conversation: {summary_text}\"}] + preserved_tail\n",
        "\n",
        "    def maybe_periodic_summarize(self, k:int, summarizer_fn):\n",
        "        \"\"\"\n",
        "        Call summarizer_fn(history) -> summary_text after every k runs.\n",
        "        \"\"\"\n",
        "        self.run_count += 1\n",
        "        if k > 0 and (self.run_count % k == 0):\n",
        "            print(f\"Periodic summarization triggered at run {self.run_count}.\")\n",
        "            summary = summarizer_fn(self.history)\n",
        "            self.replace_with_summary(summary)\n",
        "            return summary\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "RPdHuWB6PEXA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 - Summarizer (uses groq_chat_completion)\n",
        "def summarize_history_with_groq(history: List[Dict[str,str]], model=\"openai/gpt-oss-20b\") -> str:\n",
        "    # Build a prompt that instructs the model to produce a concise summary\n",
        "    conversation_text = \"\\n\\n\".join([f\"{m['role'].upper()}: {m['content']}\" for m in history])\n",
        "    prompt = (\n",
        "        \"You are a conversation summarizer. Produce a concise summary (2-4 sentences) \"\n",
        "        \"that captures the important intents, facts, and any action items mentioned in the conversation. \"\n",
        "        \"If personal details like name/email/phone were mentioned, list them briefly. \"\n",
        "        \"Keep it short and neutral.\\n\\nConversation:\\n\" + conversation_text\n",
        "    )\n",
        "    messages = [{\"role\":\"user\",\"content\":prompt}]\n",
        "    resp = groq_chat_completion(messages=messages, model=model, temperature=0.0, max_tokens=200)\n",
        "    # Groq returns a response structure like OpenAI; extract text\n",
        "    # Attempt to extract from choices\n",
        "    choices = resp.get(\"choices\") or resp.get(\"outputs\") or []\n",
        "    if choices:\n",
        "        # OpenAI-like: choices[0][\"message\"][\"content\"][\"text\"] or message.content\n",
        "        first = choices[0]\n",
        "        msg = first.get(\"message\") or first\n",
        "        # message may be dict with content field\n",
        "        if isinstance(msg, dict):\n",
        "            # Possible structures: msg[\"content\"] or msg[\"content\"][\"text\"] or msg[\"content\"][0]\n",
        "            content = \"\"\n",
        "            if \"content\" in msg:\n",
        "                c = msg[\"content\"]\n",
        "                if isinstance(c, str):\n",
        "                    content = c\n",
        "                elif isinstance(c, dict) and \"text\" in c:\n",
        "                    content = c[\"text\"]\n",
        "                elif isinstance(c, list) and len(c) > 0:\n",
        "                    content = str(c[0])\n",
        "            elif \"text\" in msg:\n",
        "                content = msg[\"text\"]\n",
        "            else:\n",
        "                content = str(msg)\n",
        "        else:\n",
        "            content = str(msg)\n",
        "    else:\n",
        "        content = \"\"\n",
        "    return content.strip() or \"(no summary produced)\"\n",
        "\n",
        "# quick local test (no API call)\n",
        "# print(summarize_history_with_groq([{\"role\":\"user\",\"content\":\"Hello\"}, {\"role\":\"assistant\",\"content\":\"Hi\"}]))\n"
      ],
      "metadata": {
        "id": "HmUOw-SyPUiI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 - Demo of Task 1\n",
        "store = ConversationStore()\n",
        "\n",
        "# Sample conversation inputs (simulate many turns)\n",
        "samples = [\n",
        "    (\"user\",\"Hi, I'm Paavan. I need help booking flights to Bangalore.\"),\n",
        "    (\"assistant\",\"Sure — when do you plan to travel and from which city?\"),\n",
        "    (\"user\",\"From Mumbai to Bangalore on Oct 15, returning Oct 20.\"),\n",
        "    (\"assistant\",\"How many passengers? Any airline preferences?\"),\n",
        "    (\"user\",\"Just me. Prefer morning flights and low-cost carriers.\"),\n",
        "    (\"assistant\",\"Got it — searching...\"),\n",
        "    (\"user\",\"Also please note my email is paavan@example.com and phone +91-98XXXXXX\"),\n",
        "    (\"assistant\",\"Thanks, I'll use that contact info for ticketing.\"),\n",
        "    (\"user\",\"Also remind me to pick up an adapter at the airport.\"),\n",
        "    (\"assistant\",\"Noted.\")\n",
        "]\n",
        "\n",
        "# Feed messages into store (multiple runs to trigger periodic summarization)\n",
        "print(\"Feeding messages into conversation store...\")\n",
        "for role, text in samples:\n",
        "    store.add_message(role, text)\n",
        "\n",
        "# Show last 3 turns truncation (n=3)\n",
        "print(\"\\n--- Last 3 turns (approx) ---\")\n",
        "for m in store.get_last_n_turns(3):\n",
        "    print(m)\n",
        "\n",
        "# Show truncation by char limit\n",
        "print(\"\\n--- By char limit 150 ---\")\n",
        "for m in store.get_by_char_limit(150):\n",
        "    print(m)\n",
        "\n",
        "# Show truncation by word limit\n",
        "print(\"\\n--- By word limit 40 ---\")\n",
        "for m in store.get_by_word_limit(40):\n",
        "    print(m)\n",
        "\n",
        "# Now demo periodic summarization: set k=3 and call maybe_periodic_summarize 3 times\n",
        "print(\"\\n--- Periodic summarization demo (k=3) ---\")\n",
        "def summarizer_fn(history):\n",
        "    # For the demo, call summarizer; to avoid real API quota usage, you may mock this\n",
        "    return summarize_history_with_groq(history)\n",
        "\n",
        "# Run three times (simulate activity), each time calling maybe_periodic_summarize\n",
        "for i in range(1,4):\n",
        "    print(f\"\\nRun {i}:\")\n",
        "    s = store.maybe_periodic_summarize(k=3, summarizer_fn=summarizer_fn)\n",
        "    if s:\n",
        "        print(\"Summary produced and stored in conversation history:\")\n",
        "        print(s)\n",
        "    else:\n",
        "        print(\"No summarization this run.\")\n",
        "\n",
        "print(\"\\nConversation history after periodic summarization:\")\n",
        "for m in store.history:\n",
        "    print(m)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4Qd-MOPPcQy",
        "outputId": "eaefae00-898e-4fbb-9359-30c0d2746888"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feeding messages into conversation store...\n",
            "\n",
            "--- Last 3 turns (approx) ---\n",
            "{'role': 'user', 'content': 'Just me. Prefer morning flights and low-cost carriers.'}\n",
            "{'role': 'assistant', 'content': 'Got it — searching...'}\n",
            "{'role': 'user', 'content': 'Also please note my email is paavan@example.com and phone +91-98XXXXXX'}\n",
            "{'role': 'assistant', 'content': \"Thanks, I'll use that contact info for ticketing.\"}\n",
            "{'role': 'user', 'content': 'Also remind me to pick up an adapter at the airport.'}\n",
            "{'role': 'assistant', 'content': 'Noted.'}\n",
            "\n",
            "--- By char limit 150 ---\n",
            "{'role': 'assistant', 'content': \"Thanks, I'll use that contact info for ticketing.\"}\n",
            "{'role': 'user', 'content': 'Also remind me to pick up an adapter at the airport.'}\n",
            "{'role': 'assistant', 'content': 'Noted.'}\n",
            "\n",
            "--- By word limit 40 ---\n",
            "{'role': 'assistant', 'content': 'Got it — searching...'}\n",
            "{'role': 'user', 'content': 'Also please note my email is paavan@example.com and phone +91-98XXXXXX'}\n",
            "{'role': 'assistant', 'content': \"Thanks, I'll use that contact info for ticketing.\"}\n",
            "{'role': 'user', 'content': 'Also remind me to pick up an adapter at the airport.'}\n",
            "{'role': 'assistant', 'content': 'Noted.'}\n",
            "\n",
            "--- Periodic summarization demo (k=3) ---\n",
            "\n",
            "Run 1:\n",
            "No summarization this run.\n",
            "\n",
            "Run 2:\n",
            "No summarization this run.\n",
            "\n",
            "Run 3:\n",
            "Periodic summarization triggered at run 3.\n",
            "Summary produced and stored in conversation history:\n",
            "Paavan requests a round‑trip flight from Mumbai to Bangalore on 15 Oct to 20 Oct, one passenger, preferring morning low‑cost carrier flights. He provided his contact details: paavan@example.com\n",
            "\n",
            "Conversation history after periodic summarization:\n",
            "{'role': 'system', 'content': 'Summary of previous conversation: Paavan requests a round‑trip flight from Mumbai to Bangalore on 15\\u202fOct\\u202fto 20\\u202fOct, one passenger, preferring morning low‑cost carrier flights. He provided his contact details: paavan@example.com'}\n",
            "{'role': 'assistant', 'content': 'Noted.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 - JSON Schema for extraction (5 fields): name, email, phone, location, age\n",
        "# We'll expose it as an OpenAI-style \"function\" with JSON schema in `functions`.\n",
        "\n",
        "extraction_function = {\n",
        "    \"name\": \"extract_contact_info\",\n",
        "    \"description\": \"Extract name, email, phone, location, age from the user chat for information collection.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\":\"string\", \"description\":\"Full name of the person if present\"},\n",
        "            \"email\": {\"type\":\"string\", \"format\":\"email\", \"description\":\"Email address if present\"},\n",
        "            \"phone\": {\"type\":\"string\", \"description\":\"Phone number if present\"},\n",
        "            \"location\": {\"type\":\"string\", \"description\":\"Location / city / country if present\"},\n",
        "            \"age\": {\"type\":\"integer\", \"minimum\":0, \"description\":\"Age if explicitly stated\"}\n",
        "        },\n",
        "        \"required\": []  # nothing strictly required; we'll accept partials\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "IWYAQniOPnt3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8 - wrapper to call chat with function-calling and parse the returned function call\n",
        "def call_extraction_function(chat_messages: List[Dict[str,str]]):\n",
        "    resp = groq_chat_completion(messages=chat_messages,\n",
        "                               model=\"openai/gpt-oss-20b\",\n",
        "                               temperature=0.0,\n",
        "                               functions=[extraction_function],\n",
        "                               function_call=\"auto\",\n",
        "                               max_tokens=400)\n",
        "    # Inspect response to find function call\n",
        "    choices = resp.get(\"choices\", [])\n",
        "    if not choices:\n",
        "        raise RuntimeError(\"No choices returned.\")\n",
        "    message = choices[0].get(\"message\") or choices[0]\n",
        "    # Function call may be in message.get(\"function_call\")\n",
        "    func_call = message.get(\"function_call\") or message.get(\"tools\") or None\n",
        "    # For compatibility, also check content\n",
        "    return {\"raw_response\": resp, \"message\": message, \"function_call\": func_call}\n",
        "\n",
        "# Demo sample chats for Task 2\n",
        "sample_chats = [\n",
        "    [{\"role\":\"user\", \"content\":\"Hello, I'm Aarti Sharma. My email is aarti.sharma@example.com and phone is +91-9876543210. I'm located in Pune and I'm 28 years old.\"}],\n",
        "    [{\"role\":\"user\", \"content\":\"Hey, this is Rohit. You can reach me at rohit123@domain.net. I live in Delhi.\"}],\n",
        "    [{\"role\":\"user\", \"content\":\"Name: Sneha. Phone: 077-555-0123. Age: 35. Email: sneha_35@mail.com. Lives in Kochi.\"}]\n",
        "]\n",
        "\n",
        "results = []\n",
        "for chat in sample_chats:\n",
        "    out = call_extraction_function(chat)\n",
        "    print(\"\\n=== Raw function_call ===\")\n",
        "    print(json.dumps(out[\"function_call\"], indent=2))\n",
        "    results.append(out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF3YhXa7PtZs",
        "outputId": "41c77fa6-ea95-46ea-c902-d2ef4e91bcda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Raw function_call ===\n",
            "{\n",
            "  \"name\": \"extract_contact_info\",\n",
            "  \"arguments\": \"{\\\"age\\\":28,\\\"email\\\":\\\"aarti.sharma@example.com\\\",\\\"location\\\":\\\"Pune\\\",\\\"name\\\":\\\"Aarti Sharma\\\",\\\"phone\\\":\\\"+91-9876543210\\\"}\"\n",
            "}\n",
            "\n",
            "=== Raw function_call ===\n",
            "{\n",
            "  \"name\": \"extract_contact_info\",\n",
            "  \"arguments\": \"{\\\"email\\\":\\\"rohit123@domain.net\\\",\\\"location\\\":\\\"Delhi\\\",\\\"name\\\":\\\"Rohit\\\"}\"\n",
            "}\n",
            "\n",
            "=== Raw function_call ===\n",
            "{\n",
            "  \"name\": \"extract_contact_info\",\n",
            "  \"arguments\": \"{\\\"age\\\":35,\\\"email\\\":\\\"sneha_35@mail.com\\\",\\\"location\\\":\\\"Kochi\\\",\\\"name\\\":\\\"Sneha\\\",\\\"phone\\\":\\\"077-555-0123\\\"}\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 - Basic manual validator that enforces types/constraints in the extraction_function\n",
        "def validate_extracted(obj: Dict[str,Any], schema: Dict[str,Any]) -> Tuple[bool, List[str]]:\n",
        "    errors = []\n",
        "    props = schema[\"parameters\"][\"properties\"]\n",
        "    for k, v in obj.items():\n",
        "        if k not in props:\n",
        "            errors.append(f\"Unknown field: {k}\")\n",
        "            continue\n",
        "        expected_type = props[k].get(\"type\")\n",
        "        if expected_type == \"integer\":\n",
        "            if not isinstance(obj[k], int):\n",
        "                # try numeric string to int\n",
        "                try:\n",
        "                    obj[k] = int(obj[k])\n",
        "                except Exception:\n",
        "                    errors.append(f\"Field {k} expected integer but got {type(obj[k]).__name__}\")\n",
        "        elif expected_type == \"string\":\n",
        "            if not isinstance(obj[k], str):\n",
        "                errors.append(f\"Field {k} expected string but got {type(obj[k]).__name__}\")\n",
        "        # basic format checks (email)\n",
        "        if props[k].get(\"format\") == \"email\" and obj.get(k):\n",
        "            if \"@\" not in obj[k]:\n",
        "                errors.append(f\"Field {k} does not look like an email: {obj[k]}\")\n",
        "    return (len(errors)==0, errors)\n",
        "\n",
        "# Parse the function call content if present\n",
        "for idx, r in enumerate(results):\n",
        "    fc = r[\"function_call\"]\n",
        "    print(f\"\\n--- Sample {idx+1} ---\")\n",
        "    if not fc:\n",
        "        print(\"No function call returned; falling back to text parse.\")\n",
        "        continue\n",
        "    # function_call could structure arguments as a JSON string in fc[\"arguments\"]\n",
        "    args = {}\n",
        "    if isinstance(fc, dict):\n",
        "        args_raw = fc.get(\"arguments\") or fc.get(\"body\") or \"\"\n",
        "        try:\n",
        "            # sometimes it's a JSON string\n",
        "            if isinstance(args_raw, str):\n",
        "                args = json.loads(args_raw)\n",
        "            elif isinstance(args_raw, dict):\n",
        "                args = args_raw\n",
        "        except Exception as e:\n",
        "            print(\"Failed to load arguments JSON:\", e)\n",
        "            args = {}\n",
        "    print(\"Parsed arguments:\", args)\n",
        "    ok, errs = validate_extracted(args, extraction_function)\n",
        "    print(\"Valid:\", ok)\n",
        "    if errs:\n",
        "        print(\"Errors:\", errs)\n",
        "    else:\n",
        "        print(\"Validated object:\", args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvX8EzZkP2op",
        "outputId": "c52b316e-9c34-47b7-a9cc-f3f2b61c1223"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample 1 ---\n",
            "Parsed arguments: {'age': 28, 'email': 'aarti.sharma@example.com', 'location': 'Pune', 'name': 'Aarti Sharma', 'phone': '+91-9876543210'}\n",
            "Valid: True\n",
            "Validated object: {'age': 28, 'email': 'aarti.sharma@example.com', 'location': 'Pune', 'name': 'Aarti Sharma', 'phone': '+91-9876543210'}\n",
            "\n",
            "--- Sample 2 ---\n",
            "Parsed arguments: {'email': 'rohit123@domain.net', 'location': 'Delhi', 'name': 'Rohit'}\n",
            "Valid: True\n",
            "Validated object: {'email': 'rohit123@domain.net', 'location': 'Delhi', 'name': 'Rohit'}\n",
            "\n",
            "--- Sample 3 ---\n",
            "Parsed arguments: {'age': 35, 'email': 'sneha_35@mail.com', 'location': 'Kochi', 'name': 'Sneha', 'phone': '077-555-0123'}\n",
            "Valid: True\n",
            "Validated object: {'age': 35, 'email': 'sneha_35@mail.com', 'location': 'Kochi', 'name': 'Sneha', 'phone': '077-555-0123'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YWNH1WzZP-3q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}